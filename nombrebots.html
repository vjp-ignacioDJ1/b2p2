<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="es">
    <head>
        <meta http-equiv="Content-Type" content="text/html;charset=UTF-8" />
        <title>nombre bots</title>
    </head>
    <body>
        <h1>
            La guerra de los ‘bots’ se libra en Wikipedia
        </h1>

        <p>Hasta 4,7 millones de los cambios que se hacen en la enciclopedia digital son correcciones que los robots se hacen continuamente entre sí</p>

        <hr/>
        <div>
            <a href="https://es-es.facebook.com/"><img src="/img/compartirFacebook.PNG" alt="compartir Facebook"/></a>
            <a href="https://twitter.com/?lang=es"><img src="/img/compartrtwiiter.PNG" alt="compartir Twitter"/></a>
        </div>
        <hr/>

        <div>
            <img src="/img/imgnombrebots.jpg" alt="imagen" width="600" height="600" />
        </div>
        <hr/>

        <p>
            Cada vez son más las páginas web que incorporan bots, programas informáticos que se comportan como humanos, para realizar tareas como responder a las preguntas de los usuarios, hacer publicidad o abrir cuentas de correo electrónico. Pero, a pesar de los esfuerzos y de su uso extendido, aún están muy lejos de actuar en la Red como lo haría una persona. Esa es la conclusión a la que ha llegado un grupo de ingenieros informáticos del Instituto Alan Turing de Reino Unido, que <a href="https://www.academia.edu/28502996/Even_Good_Bots_Fight">ha estudiado el comportamiento de estos robots en Wikipedia</a> y ha descubierto que hasta 4,7 millones de las ediciones de los artículos son correcciones que los bots se hacen constantemente entre sí, cayendo en una especie de edición sin fin nada productiva.
        </p>

        <p>
            <img src="/img/wikipedibots.PNG" alt="wiki" align="right"/>
            Los bots que trabajan en Wikipedia se encargan de tareas que pueden resultar tediosas para las personas, como identificar y deshacer casos de vandalismo, añadir enlaces, corregir la ortografía y guardar la concordancia sintáctica de las oraciones. El problema viene cuando las ediciones que hacen están condicionadas por el país y el lenguaje en el que han sido programados y están influidas por algunos aspectos culturales. Por ejemplo, algunas de estas reversiones vienen por cambiar “Palestina” por “territorio palestino” o “Golfo Pérsico” por “Golfo Arábico”, y así con varios millones de conceptos que no coinciden en las distintas regiones del mundo. 
        </p>

        <p>Además, están programados para revisar los cambios que hacen cada cierto tiempo, lo que ayuda a que se produzcan enfrentamientos con otros bots que hacen exactamente lo mismo y se corrigen entre sí cuando encuentran que su última edición ha vuelto a ser modificada. En los cambios que hacen las personas no se dan este tipo de conflictos porque los usuarios de Wikipedia rara vez vuelven a comprobar si los datos que corrigieron están actualizados.</p>

        <p>Una de las curiosidades que muestra el estudio es que el número de ediciones depende de en qué idioma esté escrito el texto. Los escritos en alemán son los que menos modificaciones sufren, con una media de 24 por entrada. En el lado contrario se encuentran los artículos en portugués, que acumulan hasta 185 reversiones por artículo. Según los expertos, una de las posibles soluciones a estas batallas interminables es que Wikipedia permita el uso de bots cooperativos que puedan gestionar los desacuerdos y permitan que las tareas se puedan cumplir de manera eficiente.</p>

    </body>
</html>